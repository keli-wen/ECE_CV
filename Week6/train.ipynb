{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n",
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "EPOCH = 40\n",
    "LR = 0.012\n",
    "DOWNLOAD_MNIST = True\n",
    "torch.manual_seed(1314)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                        download=DOWNLOAD_MNIST, )\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "\n",
    "print(train_data.data.shape)\n",
    "\n",
    "train_x = torch.unsqueeze(train_data.data, dim=1).type(torch.FloatTensor) / 255.\n",
    "train_y = train_data.targets\n",
    "print(train_x.shape)\n",
    "\n",
    "test_x = torch.unsqueeze(test_data.data, dim=1).type(torch.FloatTensor)[:2000] / 255.  # Tensor on GPU\n",
    "test_y = test_data.targets[:2000]\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "# Network 1 \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2),)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 2),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),\n",
    "                                   nn.Dropout(),)\n",
    "        self.fc1 = nn.Sequential(\n",
    "               nn.Linear(64 * 4 * 4, 256),\n",
    "               nn.BatchNorm1d(256),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout()\n",
    "            )\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "# print('\\nParameter Info:')\n",
    "# for name, parameters in cnn.named_parameters():\n",
    "#     print(name, ':', parameters.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694ef312fcbf454ca07c8db4cc8beeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.4949 | test accuracy: 0.079\n",
      "Epoch:  0 | train loss: 0.9415 | test accuracy: 0.851\n",
      "Epoch:  0 | train loss: 0.5668 | test accuracy: 0.919\n",
      "Epoch:  0 | train loss: 0.3542 | test accuracy: 0.941\n",
      "Epoch:  1 | train loss: 0.2664 | test accuracy: 0.946\n",
      "Epoch:  1 | train loss: 0.3013 | test accuracy: 0.953\n",
      "Epoch:  1 | train loss: 0.2470 | test accuracy: 0.955\n",
      "Epoch:  1 | train loss: 0.1483 | test accuracy: 0.962\n",
      "Epoch:  2 | train loss: 0.1287 | test accuracy: 0.965\n",
      "Epoch:  2 | train loss: 0.1932 | test accuracy: 0.968\n",
      "Epoch:  2 | train loss: 0.2644 | test accuracy: 0.970\n",
      "Epoch:  2 | train loss: 0.1774 | test accuracy: 0.970\n",
      "Epoch:  3 | train loss: 0.1493 | test accuracy: 0.974\n",
      "Epoch:  3 | train loss: 0.1391 | test accuracy: 0.975\n",
      "Epoch:  3 | train loss: 0.1620 | test accuracy: 0.975\n",
      "Epoch:  3 | train loss: 0.0809 | test accuracy: 0.978\n",
      "Epoch:  4 | train loss: 0.1182 | test accuracy: 0.979\n",
      "Epoch:  4 | train loss: 0.1202 | test accuracy: 0.979\n",
      "Epoch:  4 | train loss: 0.1112 | test accuracy: 0.979\n",
      "Epoch:  4 | train loss: 0.1377 | test accuracy: 0.984\n",
      "Epoch:  5 | train loss: 0.1452 | test accuracy: 0.981\n",
      "Epoch:  5 | train loss: 0.1612 | test accuracy: 0.982\n",
      "Epoch:  5 | train loss: 0.0968 | test accuracy: 0.981\n",
      "Epoch:  5 | train loss: 0.1460 | test accuracy: 0.984\n",
      "Epoch:  6 | train loss: 0.1479 | test accuracy: 0.983\n",
      "Epoch:  6 | train loss: 0.1333 | test accuracy: 0.982\n",
      "Epoch:  6 | train loss: 0.0998 | test accuracy: 0.984\n",
      "Epoch:  6 | train loss: 0.0550 | test accuracy: 0.984\n",
      "Epoch:  7 | train loss: 0.0336 | test accuracy: 0.982\n",
      "Epoch:  7 | train loss: 0.0594 | test accuracy: 0.984\n",
      "Epoch:  7 | train loss: 0.0883 | test accuracy: 0.984\n",
      "Epoch:  7 | train loss: 0.1343 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0820 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0633 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0706 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0547 | test accuracy: 0.985\n",
      "Epoch:  9 | train loss: 0.0782 | test accuracy: 0.986\n",
      "Epoch:  9 | train loss: 0.0690 | test accuracy: 0.984\n",
      "Epoch:  9 | train loss: 0.0932 | test accuracy: 0.980\n",
      "Epoch:  9 | train loss: 0.1067 | test accuracy: 0.987\n",
      "Epoch:  10 | train loss: 0.1337 | test accuracy: 0.987\n",
      "Epoch:  10 | train loss: 0.0485 | test accuracy: 0.984\n",
      "Epoch:  10 | train loss: 0.0850 | test accuracy: 0.986\n",
      "Epoch:  10 | train loss: 0.0551 | test accuracy: 0.986\n",
      "Epoch:  11 | train loss: 0.0289 | test accuracy: 0.986\n",
      "Epoch:  11 | train loss: 0.0656 | test accuracy: 0.985\n",
      "Epoch:  11 | train loss: 0.0455 | test accuracy: 0.986\n",
      "Epoch:  11 | train loss: 0.0645 | test accuracy: 0.987\n",
      "Epoch:  12 | train loss: 0.0685 | test accuracy: 0.987\n",
      "Epoch:  12 | train loss: 0.0892 | test accuracy: 0.984\n",
      "Epoch:  12 | train loss: 0.0534 | test accuracy: 0.985\n",
      "Epoch:  12 | train loss: 0.1280 | test accuracy: 0.988\n",
      "Epoch:  13 | train loss: 0.0745 | test accuracy: 0.984\n",
      "Epoch:  13 | train loss: 0.0390 | test accuracy: 0.983\n",
      "Epoch:  13 | train loss: 0.1317 | test accuracy: 0.986\n",
      "Epoch:  13 | train loss: 0.1125 | test accuracy: 0.984\n",
      "Epoch:  14 | train loss: 0.0467 | test accuracy: 0.984\n",
      "Epoch:  14 | train loss: 0.0393 | test accuracy: 0.987\n",
      "Epoch:  14 | train loss: 0.0414 | test accuracy: 0.988\n",
      "Epoch:  14 | train loss: 0.0432 | test accuracy: 0.980\n",
      "Epoch:  15 | train loss: 0.0654 | test accuracy: 0.987\n",
      "Epoch:  15 | train loss: 0.0371 | test accuracy: 0.985\n",
      "Epoch:  15 | train loss: 0.0332 | test accuracy: 0.986\n",
      "Epoch:  15 | train loss: 0.0527 | test accuracy: 0.985\n",
      "Epoch:  16 | train loss: 0.0415 | test accuracy: 0.987\n",
      "Epoch:  16 | train loss: 0.0287 | test accuracy: 0.987\n",
      "Epoch:  16 | train loss: 0.0746 | test accuracy: 0.989\n",
      "Epoch:  16 | train loss: 0.0364 | test accuracy: 0.989\n",
      "Epoch:  17 | train loss: 0.1267 | test accuracy: 0.987\n",
      "Epoch:  17 | train loss: 0.0594 | test accuracy: 0.985\n",
      "Epoch:  17 | train loss: 0.1117 | test accuracy: 0.989\n",
      "Epoch:  17 | train loss: 0.0349 | test accuracy: 0.988\n",
      "Epoch:  18 | train loss: 0.0760 | test accuracy: 0.986\n",
      "Epoch:  18 | train loss: 0.1433 | test accuracy: 0.987\n",
      "Epoch:  18 | train loss: 0.0425 | test accuracy: 0.986\n",
      "Epoch:  18 | train loss: 0.0148 | test accuracy: 0.988\n",
      "Epoch:  19 | train loss: 0.0345 | test accuracy: 0.988\n",
      "Epoch:  19 | train loss: 0.0299 | test accuracy: 0.988\n",
      "Epoch:  19 | train loss: 0.1318 | test accuracy: 0.988\n",
      "Epoch:  19 | train loss: 0.0447 | test accuracy: 0.987\n",
      "Epoch:  20 | train loss: 0.0533 | test accuracy: 0.988\n",
      "Epoch:  20 | train loss: 0.0675 | test accuracy: 0.988\n",
      "Epoch:  20 | train loss: 0.0431 | test accuracy: 0.988\n",
      "Epoch:  20 | train loss: 0.0565 | test accuracy: 0.988\n",
      "Epoch:  21 | train loss: 0.0206 | test accuracy: 0.984\n",
      "Epoch:  21 | train loss: 0.0651 | test accuracy: 0.987\n",
      "Epoch:  21 | train loss: 0.0170 | test accuracy: 0.988\n",
      "Epoch:  21 | train loss: 0.0394 | test accuracy: 0.987\n",
      "Epoch:  22 | train loss: 0.0188 | test accuracy: 0.988\n",
      "Epoch:  22 | train loss: 0.0160 | test accuracy: 0.988\n",
      "Epoch:  22 | train loss: 0.0562 | test accuracy: 0.989\n",
      "Epoch:  22 | train loss: 0.0676 | test accuracy: 0.986\n",
      "Epoch:  23 | train loss: 0.0505 | test accuracy: 0.988\n",
      "Epoch:  23 | train loss: 0.0446 | test accuracy: 0.988\n",
      "Epoch:  23 | train loss: 0.0715 | test accuracy: 0.988\n",
      "Epoch:  23 | train loss: 0.0211 | test accuracy: 0.992\n",
      "Epoch:  24 | train loss: 0.0351 | test accuracy: 0.988\n",
      "Epoch:  24 | train loss: 0.0659 | test accuracy: 0.985\n",
      "Epoch:  24 | train loss: 0.0349 | test accuracy: 0.988\n",
      "Epoch:  24 | train loss: 0.0257 | test accuracy: 0.989\n",
      "Epoch:  25 | train loss: 0.0132 | test accuracy: 0.989\n",
      "Epoch:  25 | train loss: 0.0324 | test accuracy: 0.984\n",
      "Epoch:  25 | train loss: 0.0740 | test accuracy: 0.984\n",
      "Epoch:  25 | train loss: 0.0433 | test accuracy: 0.990\n",
      "Epoch:  26 | train loss: 0.0320 | test accuracy: 0.989\n",
      "Epoch:  26 | train loss: 0.0259 | test accuracy: 0.987\n",
      "Epoch:  26 | train loss: 0.0347 | test accuracy: 0.989\n",
      "Epoch:  26 | train loss: 0.0357 | test accuracy: 0.988\n",
      "Epoch:  27 | train loss: 0.0233 | test accuracy: 0.988\n",
      "Epoch:  27 | train loss: 0.0442 | test accuracy: 0.987\n",
      "Epoch:  27 | train loss: 0.1144 | test accuracy: 0.988\n",
      "Epoch:  27 | train loss: 0.0277 | test accuracy: 0.988\n",
      "Epoch:  28 | train loss: 0.0531 | test accuracy: 0.988\n",
      "Epoch:  28 | train loss: 0.0119 | test accuracy: 0.990\n",
      "Epoch:  28 | train loss: 0.0464 | test accuracy: 0.988\n",
      "Epoch:  28 | train loss: 0.0730 | test accuracy: 0.989\n",
      "Epoch:  29 | train loss: 0.0179 | test accuracy: 0.988\n",
      "Epoch:  29 | train loss: 0.0223 | test accuracy: 0.989\n",
      "Epoch:  29 | train loss: 0.0247 | test accuracy: 0.990\n",
      "Epoch:  29 | train loss: 0.0457 | test accuracy: 0.990\n",
      "Epoch:  30 | train loss: 0.0577 | test accuracy: 0.989\n",
      "Epoch:  30 | train loss: 0.0256 | test accuracy: 0.989\n",
      "Epoch:  30 | train loss: 0.0331 | test accuracy: 0.988\n",
      "Epoch:  30 | train loss: 0.0192 | test accuracy: 0.990\n",
      "Epoch:  31 | train loss: 0.0152 | test accuracy: 0.988\n",
      "Epoch:  31 | train loss: 0.0436 | test accuracy: 0.987\n",
      "Epoch:  31 | train loss: 0.0472 | test accuracy: 0.988\n",
      "Epoch:  31 | train loss: 0.0068 | test accuracy: 0.990\n",
      "Epoch:  32 | train loss: 0.0314 | test accuracy: 0.989\n",
      "Epoch:  32 | train loss: 0.0101 | test accuracy: 0.989\n",
      "Epoch:  32 | train loss: 0.0377 | test accuracy: 0.987\n",
      "Epoch:  32 | train loss: 0.0338 | test accuracy: 0.989\n",
      "Epoch:  33 | train loss: 0.0116 | test accuracy: 0.990\n",
      "Epoch:  33 | train loss: 0.0353 | test accuracy: 0.991\n",
      "Epoch:  33 | train loss: 0.0089 | test accuracy: 0.984\n",
      "Epoch:  33 | train loss: 0.0324 | test accuracy: 0.989\n",
      "Epoch:  34 | train loss: 0.0188 | test accuracy: 0.988\n",
      "Epoch:  34 | train loss: 0.0280 | test accuracy: 0.987\n",
      "Epoch:  34 | train loss: 0.0188 | test accuracy: 0.988\n",
      "Epoch:  34 | train loss: 0.0288 | test accuracy: 0.988\n",
      "Epoch:  35 | train loss: 0.0365 | test accuracy: 0.988\n",
      "Epoch:  35 | train loss: 0.0358 | test accuracy: 0.987\n",
      "Epoch:  35 | train loss: 0.0622 | test accuracy: 0.985\n",
      "Epoch:  35 | train loss: 0.0235 | test accuracy: 0.988\n",
      "Epoch:  36 | train loss: 0.0141 | test accuracy: 0.990\n",
      "Epoch:  36 | train loss: 0.0246 | test accuracy: 0.988\n",
      "Epoch:  36 | train loss: 0.0167 | test accuracy: 0.989\n",
      "Epoch:  36 | train loss: 0.0148 | test accuracy: 0.991\n",
      "Epoch:  37 | train loss: 0.0202 | test accuracy: 0.989\n",
      "Epoch:  37 | train loss: 0.0332 | test accuracy: 0.988\n",
      "Epoch:  37 | train loss: 0.0093 | test accuracy: 0.989\n",
      "Epoch:  37 | train loss: 0.0234 | test accuracy: 0.988\n",
      "Epoch:  38 | train loss: 0.0143 | test accuracy: 0.988\n",
      "Epoch:  38 | train loss: 0.0362 | test accuracy: 0.990\n",
      "Epoch:  38 | train loss: 0.0293 | test accuracy: 0.992\n",
      "Epoch:  38 | train loss: 0.0610 | test accuracy: 0.988\n",
      "Epoch:  39 | train loss: 0.0603 | test accuracy: 0.989\n",
      "Epoch:  39 | train loss: 0.0284 | test accuracy: 0.989\n",
      "Epoch:  39 | train loss: 0.0273 | test accuracy: 0.989\n",
      "Epoch:  39 | train loss: 0.0121 | test accuracy: 0.990\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') prediction number\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') real number\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "data_size = 60000\n",
    "batch_size = 150\n",
    "\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    random_indx = np.random.permutation(data_size)\n",
    "    for batch_i in range(data_size // batch_size):\n",
    "        model.train()\n",
    "        indx = random_indx[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "\n",
    "        b_x = train_x[indx, :]\n",
    "        b_y = train_y[indx]\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "#         print(b_x.shape)\n",
    "#         print(b_y.shape)\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        output = model(b_x)\n",
    "    \n",
    "        loss = loss_func(output, b_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_i % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_output = model(test_x)\n",
    "                pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                # pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.3f' % accuracy)\n",
    "\n",
    "test_output = model(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n",
    "\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deeplearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "308b7885773b59ea1689ca96567743a23403c24d4583cda29c67ac2514491ae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

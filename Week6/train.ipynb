{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n",
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "EPOCH = 40\n",
    "LR = 0.012\n",
    "DOWNLOAD_MNIST = True\n",
    "torch.manual_seed(1314)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                        download=DOWNLOAD_MNIST, )\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "\n",
    "print(train_data.data.shape)\n",
    "\n",
    "train_x = torch.unsqueeze(train_data.data, dim=1).type(torch.FloatTensor) / 255.\n",
    "train_y = train_data.targets\n",
    "print(train_x.shape)\n",
    "\n",
    "test_x = torch.unsqueeze(test_data.data, dim=1).type(torch.FloatTensor)[:2000] / 255.  # Tensor on GPU\n",
    "test_y = test_data.targets[:2000]\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "# Network 1 \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2),)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 2),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),\n",
    "                                   nn.Dropout(),)\n",
    "        self.fc1 = nn.Sequential(\n",
    "               nn.Linear(64 * 4 * 4, 256),\n",
    "               nn.BatchNorm1d(256),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout()\n",
    "            )\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "# print('\\nParameter Info:')\n",
    "# for name, parameters in cnn.named_parameters():\n",
    "#     print(name, ':', parameters.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522646107e014d9291d6c47dc8d5dccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3905 | test accuracy: 0.088\n",
      "Epoch:  0 | train loss: 1.3625 | test accuracy: 0.777\n",
      "Epoch:  0 | train loss: 0.8571 | test accuracy: 0.879\n",
      "Epoch:  0 | train loss: 0.6283 | test accuracy: 0.918\n",
      "Epoch:  1 | train loss: 0.4555 | test accuracy: 0.933\n",
      "Epoch:  1 | train loss: 0.3110 | test accuracy: 0.937\n",
      "Epoch:  1 | train loss: 0.3328 | test accuracy: 0.945\n",
      "Epoch:  1 | train loss: 0.3346 | test accuracy: 0.953\n",
      "Epoch:  2 | train loss: 0.3430 | test accuracy: 0.957\n",
      "Epoch:  2 | train loss: 0.2941 | test accuracy: 0.962\n",
      "Epoch:  2 | train loss: 0.2162 | test accuracy: 0.966\n",
      "Epoch:  2 | train loss: 0.1761 | test accuracy: 0.968\n",
      "Epoch:  3 | train loss: 0.1955 | test accuracy: 0.970\n",
      "Epoch:  3 | train loss: 0.1642 | test accuracy: 0.971\n",
      "Epoch:  3 | train loss: 0.1215 | test accuracy: 0.973\n",
      "Epoch:  3 | train loss: 0.1752 | test accuracy: 0.973\n",
      "Epoch:  4 | train loss: 0.1525 | test accuracy: 0.975\n",
      "Epoch:  4 | train loss: 0.1638 | test accuracy: 0.974\n",
      "Epoch:  4 | train loss: 0.1649 | test accuracy: 0.975\n",
      "Epoch:  4 | train loss: 0.1573 | test accuracy: 0.975\n",
      "Epoch:  5 | train loss: 0.1745 | test accuracy: 0.978\n",
      "Epoch:  5 | train loss: 0.1121 | test accuracy: 0.978\n",
      "Epoch:  5 | train loss: 0.0958 | test accuracy: 0.978\n",
      "Epoch:  5 | train loss: 0.1574 | test accuracy: 0.979\n",
      "Epoch:  6 | train loss: 0.1274 | test accuracy: 0.982\n",
      "Epoch:  6 | train loss: 0.0669 | test accuracy: 0.981\n",
      "Epoch:  6 | train loss: 0.0879 | test accuracy: 0.980\n",
      "Epoch:  6 | train loss: 0.1113 | test accuracy: 0.982\n",
      "Epoch:  7 | train loss: 0.1539 | test accuracy: 0.980\n",
      "Epoch:  7 | train loss: 0.1095 | test accuracy: 0.983\n",
      "Epoch:  7 | train loss: 0.1286 | test accuracy: 0.983\n",
      "Epoch:  7 | train loss: 0.1281 | test accuracy: 0.983\n",
      "Epoch:  8 | train loss: 0.0669 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0561 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.0840 | test accuracy: 0.984\n",
      "Epoch:  8 | train loss: 0.1331 | test accuracy: 0.985\n",
      "Epoch:  9 | train loss: 0.0953 | test accuracy: 0.985\n",
      "Epoch:  9 | train loss: 0.0823 | test accuracy: 0.981\n",
      "Epoch:  9 | train loss: 0.1009 | test accuracy: 0.982\n",
      "Epoch:  9 | train loss: 0.0659 | test accuracy: 0.983\n",
      "Epoch:  10 | train loss: 0.1316 | test accuracy: 0.987\n",
      "Epoch:  10 | train loss: 0.0909 | test accuracy: 0.987\n",
      "Epoch:  10 | train loss: 0.0667 | test accuracy: 0.984\n",
      "Epoch:  10 | train loss: 0.0714 | test accuracy: 0.985\n",
      "Epoch:  11 | train loss: 0.0668 | test accuracy: 0.985\n",
      "Epoch:  11 | train loss: 0.0501 | test accuracy: 0.985\n",
      "Epoch:  11 | train loss: 0.0906 | test accuracy: 0.984\n",
      "Epoch:  11 | train loss: 0.0666 | test accuracy: 0.984\n",
      "Epoch:  12 | train loss: 0.0243 | test accuracy: 0.987\n",
      "Epoch:  12 | train loss: 0.0784 | test accuracy: 0.987\n",
      "Epoch:  12 | train loss: 0.0828 | test accuracy: 0.987\n",
      "Epoch:  12 | train loss: 0.0436 | test accuracy: 0.987\n",
      "Epoch:  13 | train loss: 0.0509 | test accuracy: 0.987\n",
      "Epoch:  13 | train loss: 0.0485 | test accuracy: 0.985\n",
      "Epoch:  13 | train loss: 0.0661 | test accuracy: 0.987\n",
      "Epoch:  13 | train loss: 0.0347 | test accuracy: 0.988\n",
      "Epoch:  14 | train loss: 0.0664 | test accuracy: 0.987\n",
      "Epoch:  14 | train loss: 0.0282 | test accuracy: 0.987\n",
      "Epoch:  14 | train loss: 0.0739 | test accuracy: 0.988\n",
      "Epoch:  14 | train loss: 0.0673 | test accuracy: 0.985\n",
      "Epoch:  15 | train loss: 0.0574 | test accuracy: 0.987\n",
      "Epoch:  15 | train loss: 0.0651 | test accuracy: 0.988\n",
      "Epoch:  15 | train loss: 0.0540 | test accuracy: 0.985\n",
      "Epoch:  15 | train loss: 0.0459 | test accuracy: 0.988\n",
      "Epoch:  16 | train loss: 0.0820 | test accuracy: 0.987\n",
      "Epoch:  16 | train loss: 0.0967 | test accuracy: 0.985\n",
      "Epoch:  16 | train loss: 0.0756 | test accuracy: 0.987\n",
      "Epoch:  16 | train loss: 0.0422 | test accuracy: 0.987\n",
      "Epoch:  17 | train loss: 0.0873 | test accuracy: 0.987\n",
      "Epoch:  17 | train loss: 0.0527 | test accuracy: 0.988\n",
      "Epoch:  17 | train loss: 0.1083 | test accuracy: 0.987\n",
      "Epoch:  17 | train loss: 0.0414 | test accuracy: 0.987\n",
      "Epoch:  18 | train loss: 0.1094 | test accuracy: 0.988\n",
      "Epoch:  18 | train loss: 0.0487 | test accuracy: 0.988\n",
      "Epoch:  18 | train loss: 0.0816 | test accuracy: 0.988\n",
      "Epoch:  18 | train loss: 0.0245 | test accuracy: 0.987\n",
      "Epoch:  19 | train loss: 0.0382 | test accuracy: 0.989\n",
      "Epoch:  19 | train loss: 0.0363 | test accuracy: 0.989\n",
      "Epoch:  19 | train loss: 0.0458 | test accuracy: 0.988\n",
      "Epoch:  19 | train loss: 0.0512 | test accuracy: 0.987\n",
      "Epoch:  20 | train loss: 0.0992 | test accuracy: 0.988\n",
      "Epoch:  20 | train loss: 0.0802 | test accuracy: 0.988\n",
      "Epoch:  20 | train loss: 0.0565 | test accuracy: 0.987\n",
      "Epoch:  20 | train loss: 0.0683 | test accuracy: 0.987\n",
      "Epoch:  21 | train loss: 0.0379 | test accuracy: 0.988\n",
      "Epoch:  21 | train loss: 0.0688 | test accuracy: 0.987\n",
      "Epoch:  21 | train loss: 0.0842 | test accuracy: 0.985\n",
      "Epoch:  21 | train loss: 0.0800 | test accuracy: 0.988\n",
      "Epoch:  22 | train loss: 0.0495 | test accuracy: 0.989\n",
      "Epoch:  22 | train loss: 0.0340 | test accuracy: 0.987\n",
      "Epoch:  22 | train loss: 0.0576 | test accuracy: 0.988\n",
      "Epoch:  22 | train loss: 0.0546 | test accuracy: 0.988\n",
      "Epoch:  23 | train loss: 0.0213 | test accuracy: 0.986\n",
      "Epoch:  23 | train loss: 0.0322 | test accuracy: 0.989\n",
      "Epoch:  23 | train loss: 0.0342 | test accuracy: 0.988\n",
      "Epoch:  23 | train loss: 0.0476 | test accuracy: 0.990\n",
      "Epoch:  24 | train loss: 0.0469 | test accuracy: 0.987\n",
      "Epoch:  24 | train loss: 0.0392 | test accuracy: 0.988\n",
      "Epoch:  24 | train loss: 0.0461 | test accuracy: 0.987\n",
      "Epoch:  24 | train loss: 0.0879 | test accuracy: 0.988\n",
      "Epoch:  25 | train loss: 0.0291 | test accuracy: 0.988\n",
      "Epoch:  25 | train loss: 0.0660 | test accuracy: 0.988\n",
      "Epoch:  25 | train loss: 0.0456 | test accuracy: 0.988\n",
      "Epoch:  25 | train loss: 0.0421 | test accuracy: 0.988\n",
      "Epoch:  26 | train loss: 0.0527 | test accuracy: 0.986\n",
      "Epoch:  26 | train loss: 0.0353 | test accuracy: 0.987\n",
      "Epoch:  26 | train loss: 0.0825 | test accuracy: 0.989\n",
      "Epoch:  26 | train loss: 0.0438 | test accuracy: 0.985\n",
      "Epoch:  27 | train loss: 0.0588 | test accuracy: 0.985\n",
      "Epoch:  27 | train loss: 0.0269 | test accuracy: 0.988\n",
      "Epoch:  27 | train loss: 0.0418 | test accuracy: 0.988\n",
      "Epoch:  27 | train loss: 0.0262 | test accuracy: 0.986\n",
      "Epoch:  28 | train loss: 0.0560 | test accuracy: 0.988\n",
      "Epoch:  28 | train loss: 0.0230 | test accuracy: 0.988\n",
      "Epoch:  28 | train loss: 0.0159 | test accuracy: 0.987\n",
      "Epoch:  28 | train loss: 0.0108 | test accuracy: 0.989\n",
      "Epoch:  29 | train loss: 0.0315 | test accuracy: 0.990\n",
      "Epoch:  29 | train loss: 0.0308 | test accuracy: 0.988\n",
      "Epoch:  29 | train loss: 0.0672 | test accuracy: 0.987\n",
      "Epoch:  29 | train loss: 0.0178 | test accuracy: 0.990\n",
      "Epoch:  30 | train loss: 0.0662 | test accuracy: 0.989\n",
      "Epoch:  30 | train loss: 0.0272 | test accuracy: 0.988\n",
      "Epoch:  30 | train loss: 0.0626 | test accuracy: 0.989\n",
      "Epoch:  30 | train loss: 0.0291 | test accuracy: 0.988\n",
      "Epoch:  31 | train loss: 0.0295 | test accuracy: 0.989\n",
      "Epoch:  31 | train loss: 0.0547 | test accuracy: 0.987\n",
      "Epoch:  31 | train loss: 0.0599 | test accuracy: 0.989\n",
      "Epoch:  31 | train loss: 0.0321 | test accuracy: 0.988\n",
      "Epoch:  32 | train loss: 0.0200 | test accuracy: 0.989\n",
      "Epoch:  32 | train loss: 0.0222 | test accuracy: 0.990\n",
      "Epoch:  32 | train loss: 0.0191 | test accuracy: 0.987\n",
      "Epoch:  32 | train loss: 0.0271 | test accuracy: 0.988\n",
      "Epoch:  33 | train loss: 0.0308 | test accuracy: 0.985\n",
      "Epoch:  33 | train loss: 0.0777 | test accuracy: 0.989\n",
      "Epoch:  33 | train loss: 0.0428 | test accuracy: 0.988\n",
      "Epoch:  33 | train loss: 0.0458 | test accuracy: 0.990\n",
      "Epoch:  34 | train loss: 0.0554 | test accuracy: 0.987\n",
      "Epoch:  34 | train loss: 0.0397 | test accuracy: 0.990\n",
      "Epoch:  34 | train loss: 0.0747 | test accuracy: 0.988\n",
      "Epoch:  34 | train loss: 0.0376 | test accuracy: 0.988\n",
      "Epoch:  35 | train loss: 0.0131 | test accuracy: 0.989\n",
      "Epoch:  35 | train loss: 0.0943 | test accuracy: 0.991\n",
      "Epoch:  35 | train loss: 0.0352 | test accuracy: 0.987\n",
      "Epoch:  35 | train loss: 0.0177 | test accuracy: 0.988\n",
      "Epoch:  36 | train loss: 0.1028 | test accuracy: 0.987\n",
      "Epoch:  36 | train loss: 0.1392 | test accuracy: 0.991\n",
      "Epoch:  36 | train loss: 0.0183 | test accuracy: 0.987\n",
      "Epoch:  36 | train loss: 0.0237 | test accuracy: 0.989\n",
      "Epoch:  37 | train loss: 0.0368 | test accuracy: 0.989\n",
      "Epoch:  37 | train loss: 0.0205 | test accuracy: 0.989\n",
      "Epoch:  37 | train loss: 0.0211 | test accuracy: 0.988\n",
      "Epoch:  37 | train loss: 0.0729 | test accuracy: 0.989\n",
      "Epoch:  38 | train loss: 0.0230 | test accuracy: 0.989\n",
      "Epoch:  38 | train loss: 0.0540 | test accuracy: 0.991\n",
      "Epoch:  38 | train loss: 0.0211 | test accuracy: 0.988\n",
      "Epoch:  38 | train loss: 0.0478 | test accuracy: 0.987\n",
      "Epoch:  39 | train loss: 0.0109 | test accuracy: 0.989\n",
      "Epoch:  39 | train loss: 0.0407 | test accuracy: 0.988\n",
      "Epoch:  39 | train loss: 0.0214 | test accuracy: 0.988\n",
      "Epoch:  39 | train loss: 0.0389 | test accuracy: 0.988\n",
      "Epoch:  40 | train loss: 0.0149 | test accuracy: 0.990\n",
      "Epoch:  40 | train loss: 0.0252 | test accuracy: 0.989\n",
      "Epoch:  40 | train loss: 0.0093 | test accuracy: 0.992\n",
      "Epoch:  40 | train loss: 0.0156 | test accuracy: 0.991\n",
      "Epoch:  41 | train loss: 0.0484 | test accuracy: 0.986\n",
      "Epoch:  41 | train loss: 0.1346 | test accuracy: 0.989\n",
      "Epoch:  41 | train loss: 0.0137 | test accuracy: 0.988\n",
      "Epoch:  41 | train loss: 0.0243 | test accuracy: 0.990\n",
      "Epoch:  42 | train loss: 0.0341 | test accuracy: 0.990\n",
      "Epoch:  42 | train loss: 0.0155 | test accuracy: 0.988\n",
      "Epoch:  42 | train loss: 0.0824 | test accuracy: 0.990\n",
      "Epoch:  42 | train loss: 0.0198 | test accuracy: 0.990\n",
      "Epoch:  43 | train loss: 0.0152 | test accuracy: 0.988\n",
      "Epoch:  43 | train loss: 0.0450 | test accuracy: 0.990\n",
      "Epoch:  43 | train loss: 0.0991 | test accuracy: 0.987\n",
      "Epoch:  43 | train loss: 0.0066 | test accuracy: 0.988\n",
      "Epoch:  44 | train loss: 0.0245 | test accuracy: 0.988\n",
      "Epoch:  44 | train loss: 0.0931 | test accuracy: 0.988\n",
      "Epoch:  44 | train loss: 0.0975 | test accuracy: 0.989\n",
      "Epoch:  44 | train loss: 0.0238 | test accuracy: 0.989\n",
      "Epoch:  45 | train loss: 0.0199 | test accuracy: 0.989\n",
      "Epoch:  45 | train loss: 0.0171 | test accuracy: 0.989\n",
      "Epoch:  45 | train loss: 0.0352 | test accuracy: 0.987\n",
      "Epoch:  45 | train loss: 0.0457 | test accuracy: 0.989\n",
      "Epoch:  46 | train loss: 0.0327 | test accuracy: 0.990\n",
      "Epoch:  46 | train loss: 0.0393 | test accuracy: 0.989\n",
      "Epoch:  46 | train loss: 0.0701 | test accuracy: 0.989\n",
      "Epoch:  46 | train loss: 0.0411 | test accuracy: 0.991\n",
      "Epoch:  47 | train loss: 0.0453 | test accuracy: 0.988\n",
      "Epoch:  47 | train loss: 0.0078 | test accuracy: 0.989\n",
      "Epoch:  47 | train loss: 0.0275 | test accuracy: 0.989\n",
      "Epoch:  47 | train loss: 0.0410 | test accuracy: 0.989\n",
      "Epoch:  48 | train loss: 0.0073 | test accuracy: 0.990\n",
      "Epoch:  48 | train loss: 0.0637 | test accuracy: 0.990\n",
      "Epoch:  48 | train loss: 0.0341 | test accuracy: 0.987\n",
      "Epoch:  48 | train loss: 0.0200 | test accuracy: 0.990\n",
      "Epoch:  49 | train loss: 0.0095 | test accuracy: 0.988\n",
      "Epoch:  49 | train loss: 0.0383 | test accuracy: 0.989\n",
      "Epoch:  49 | train loss: 0.0152 | test accuracy: 0.988\n",
      "Epoch:  49 | train loss: 0.0313 | test accuracy: 0.989\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') prediction number\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') real number\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "data_size = 60000\n",
    "batch_size = 150\n",
    "\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    random_indx = np.random.permutation(data_size)\n",
    "    for batch_i in range(data_size // batch_size):\n",
    "        model.train()\n",
    "        indx = random_indx[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "\n",
    "        b_x = train_x[indx, :]\n",
    "        b_y = train_y[indx]\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "#         print(b_x.shape)\n",
    "#         print(b_y.shape)\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        output = model(b_x)\n",
    "    \n",
    "        loss = loss_func(output, b_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_i % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_output = model(test_x)\n",
    "                pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                # pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "                accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.3f' % accuracy)\n",
    "\n",
    "test_output = model(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n",
    "\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deeplearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "308b7885773b59ea1689ca96567743a23403c24d4583cda29c67ac2514491ae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
